"""
Test especÃ­fico para validar el manejo de mÃºltiples PDFs
Prueba cÃ³mo el LLM entiende y diferencia mÃºltiples documentos
"""
import asyncio
import sys
import os
from pdf_chat_session import create_session

class MultiplePDFTester:
    """Tester especÃ­fico para mÃºltiples PDFs"""
    
    def __init__(self):
        self.test_pdfs = {
            'prueba1': '/home/parrot/bot-trascription/pdfs_pruebas/prueba1/JEFES, JEFAS Y ENCARGADOS.pdf',
            'prueba2_doc1': '/home/parrot/bot-trascription/pdfs_pruebas/prueba2/OFICIO 2006-25 JEFA, JEFES Y ENCARGDOS DE SECTOR INFORMACIÃ“N SOBRE LOS EIA.pdf',
            'prueba2_doc2': '/home/parrot/bot-trascription/pdfs_pruebas/prueba2/VACUNA VHP.pdf'
        }
    
    async def test_single_pdf_clarity(self):
        """Test: Un solo PDF - verificar claridad del prompt"""
        print("ðŸ“„ Test 1: UN SOLO PDF")
        print("=" * 50)
        
        session = create_session("test_single_pdf")
        
        # Cargar un PDF
        if not session.load_pdf(self.test_pdfs['prueba1'], "Documento_Jefes.pdf"):
            print("âŒ Error cargando PDF")
            return False
        
        print(f"âœ… PDF cargado: {len(session.pdfs)} documento(s)")
        print(f"ðŸ“Š Contenido combinado: {len(session.combined_pdf_content)} caracteres")
        
        # Ver cÃ³mo se ve el prompt
        prompt_preview = session.combined_pdf_content[:500] + "..." if len(session.combined_pdf_content) > 500 else session.combined_pdf_content
        print(f"\nðŸ” Vista previa del contenido combinado:")
        print("-" * 50)
        print(prompt_preview)
        print("-" * 50)
        
        # Probar chat
        result = await session.chat("Â¿De quÃ© trata este documento?")
        if result['success']:
            print(f"\nðŸ¤– Respuesta: {result['response'][:200]}...")
            print(f"ðŸ“Š Tokens usados: {result['token_info']['total_exchange_tokens']:,}")
        else:
            print(f"âŒ Error en chat: {result['error']}")
            return False
        
        return True
    
    async def test_multiple_pdfs_clarity(self):
        """Test: MÃºltiples PDFs - verificar que el LLM los diferencia"""
        print("\nðŸ“„ðŸ“„ Test 2: MÃšLTIPLES PDFs")
        print("=" * 50)
        
        session = create_session("test_multiple_pdfs")
        
        # Cargar primer PDF
        if not session.load_pdf(self.test_pdfs['prueba2_doc1'], "Oficio_EIA.pdf"):
            print("âŒ Error cargando primer PDF")
            return False
        
        print(f"âœ… Primer PDF cargado: {len(session.pdfs)} documento(s)")
        
        # Cargar segundo PDF
        if not session.load_pdf(self.test_pdfs['prueba2_doc2'], "Vacuna_VHP.pdf"):
            print("âŒ Error cargando segundo PDF")
            return False
        
        print(f"âœ… Segundo PDF cargado: {len(session.pdfs)} documento(s)")
        print(f"ðŸ“Š Contenido combinado: {len(session.combined_pdf_content)} caracteres")
        
        # Ver cÃ³mo se ve el contenido combinado
        print(f"\nðŸ” Estructura del contenido combinado:")
        print("-" * 50)
        lines = session.combined_pdf_content.split('\n')
        for i, line in enumerate(lines[:20]):  # Primeras 20 lÃ­neas
            print(f"{i+1:2d}: {line}")
        print("... (contenido truncado)")
        print("-" * 50)
        
        # Preguntas especÃ­ficas para probar diferenciaciÃ³n
        test_questions = [
            "Â¿CuÃ¡ntos documentos tienes cargados?",
            "Â¿CuÃ¡les son los nombres de los documentos?",
            "Â¿De quÃ© trata cada documento?",
            "Â¿Hay informaciÃ³n sobre vacunas en algÃºn documento?",
            "Â¿Hay informaciÃ³n sobre EIA en algÃºn documento?",
            "Dame un resumen de cada documento por separado"
        ]
        
        print(f"\nðŸŽ¯ Probando {len(test_questions)} preguntas de diferenciaciÃ³n:")
        
        for i, question in enumerate(test_questions, 1):
            print(f"\n--- Pregunta {i}/{len(test_questions)} ---")
            print(f"â“ {question}")
            
            result = await session.chat(question)
            if result['success']:
                response = result['response']
                print(f"ðŸ¤– Respuesta: {response[:300]}...")
                
                # Verificar si menciona mÃºltiples documentos
                multiple_indicators = [
                    "documento", "documentos", "primer", "segundo", 
                    "Oficio", "Vacuna", "EIA", "VHP", "#1", "#2"
                ]
                indicators_found = sum(1 for indicator in multiple_indicators if indicator.lower() in response.lower())
                print(f"ðŸ“Š Indicadores de mÃºltiples docs: {indicators_found}/{len(multiple_indicators)}")
                print(f"ðŸ“Š Tokens: {result['token_info']['total_exchange_tokens']:,}")
                
                if indicators_found >= 3:
                    print("âœ… Parece entender mÃºltiples documentos")
                else:
                    print("âš ï¸ Posible confusiÃ³n con mÃºltiples documentos")
            else:
                print(f"âŒ Error: {result['error']}")
                return False
        
        return True
    
    async def test_prompt_structure_analysis(self):
        """Test: Analizar la estructura del prompt que recibe el LLM"""
        print("\nðŸ” Test 3: ANÃLISIS DE ESTRUCTURA DEL PROMPT")
        print("=" * 50)
        
        session = create_session("test_prompt_analysis")
        
        # Cargar mÃºltiples PDFs
        session.load_pdf(self.test_pdfs['prueba2_doc1'], "Doc1_Oficio.pdf")
        session.load_pdf(self.test_pdfs['prueba2_doc2'], "Doc2_Vacuna.pdf")
        
        # Obtener el prompt completo que se envÃ­a al LLM
        from llm_client import get_gemini_client
        llm_client = get_gemini_client()
        
        full_prompt = llm_client.get_system_prompt(session.combined_pdf_content)
        
        print(f"ðŸ“Š EstadÃ­sticas del prompt:")
        print(f"   - Longitud total: {len(full_prompt):,} caracteres")
        print(f"   - Tokens estimados: {llm_client.estimate_tokens(full_prompt):,}")
        print(f"   - Contiene 'MÃšLTIPLES': {'âœ…' if 'MÃšLTIPLES' in full_prompt else 'âŒ'}")
        print(f"   - Contiene 'DOCUMENTO #1': {'âœ…' if 'DOCUMENTO #1' in full_prompt else 'âŒ'}")
        print(f"   - Contiene 'DOCUMENTO #2': {'âœ…' if 'DOCUMENTO #2' in full_prompt else 'âŒ'}")
        
        # Mostrar estructura del prompt
        print(f"\nðŸ” Estructura del prompt (primeras 1000 caracteres):")
        print("-" * 70)
        print(full_prompt[:1000])
        print("... (contenido truncado)")
        print("-" * 70)
        
        # Buscar secciones clave
        key_sections = [
            "DOCUMENTOS PDF CARGADOS:",
            "INSTRUCCIONES ESPECIALES:",
            "DOCUMENTO #1:",
            "DOCUMENTO #2:",
            "FIN DEL DOCUMENTO"
        ]
        
        print(f"\nðŸ” Secciones clave encontradas:")
        for section in key_sections:
            found = section in full_prompt
            print(f"   - {section}: {'âœ…' if found else 'âŒ'}")
        
        return True
    
    async def test_pdf_removal_and_rebuilding(self):
        """Test: Verificar que la eliminaciÃ³n y reconstrucciÃ³n funciona"""
        print("\nðŸ—‘ï¸ Test 4: ELIMINACIÃ“N Y RECONSTRUCCIÃ“N")
        print("=" * 50)
        
        session = create_session("test_pdf_removal")
        
        # Cargar mÃºltiples PDFs
        session.load_pdf(self.test_pdfs['prueba2_doc1'], "Doc_A.pdf")
        session.load_pdf(self.test_pdfs['prueba2_doc2'], "Doc_B.pdf")
        
        print(f"âœ… Cargados: {len(session.pdfs)} PDFs")
        original_content_length = len(session.combined_pdf_content)
        print(f"ðŸ“Š Contenido original: {original_content_length:,} caracteres")
        
        # Eliminar un PDF
        removed = session.remove_pdf("Doc_A.pdf")
        print(f"ðŸ—‘ï¸ PDF eliminado: {'âœ…' if removed else 'âŒ'}")
        print(f"ðŸ“Š PDFs restantes: {len(session.pdfs)}")
        
        new_content_length = len(session.combined_pdf_content) if session.combined_pdf_content else 0
        print(f"ðŸ“Š Contenido despuÃ©s: {new_content_length:,} caracteres")
        
        # Verificar que el contenido se reconstruyÃ³ correctamente
        if new_content_length > 0 and new_content_length < original_content_length:
            print("âœ… Contenido reconstruido correctamente")
        else:
            print("âŒ Problema en la reconstrucciÃ³n del contenido")
            return False
        
        # Probar chat despuÃ©s de eliminaciÃ³n
        result = await session.chat("Â¿CuÃ¡ntos documentos tienes ahora?")
        if result['success']:
            print(f"ðŸ¤– Respuesta despuÃ©s de eliminaciÃ³n: {result['response'][:150]}...")
        else:
            print(f"âŒ Error en chat despuÃ©s de eliminaciÃ³n: {result['error']}")
            return False
        
        return True

async def main():
    """Ejecutar todos los tests de mÃºltiples PDFs"""
    print("ðŸ§ª TESTS DE MÃšLTIPLES PDFs - ValidaciÃ³n de ComprensiÃ³n del LLM")
    print("=" * 80)
    
    tester = MultiplePDFTester()
    
    # Verificar que los PDFs existen
    missing_pdfs = []
    for name, path in tester.test_pdfs.items():
        if not os.path.exists(path):
            missing_pdfs.append(f"{name}: {path}")
    
    if missing_pdfs:
        print("âŒ PDFs de prueba no encontrados:")
        for missing in missing_pdfs:
            print(f"   - {missing}")
        return 1
    
    print("âœ… Todos los PDFs de prueba encontrados")
    
    # Ejecutar tests
    tests = [
        ("Un Solo PDF", tester.test_single_pdf_clarity),
        ("MÃºltiples PDFs", tester.test_multiple_pdfs_clarity),
        ("AnÃ¡lisis de Prompt", tester.test_prompt_structure_analysis),
        ("EliminaciÃ³n y ReconstrucciÃ³n", tester.test_pdf_removal_and_rebuilding),
    ]
    
    passed = 0
    for test_name, test_func in tests:
        try:
            print(f"\n{'='*20} {test_name.upper()} {'='*20}")
            if await test_func():
                passed += 1
                print(f"âœ… {test_name} - PASÃ“")
            else:
                print(f"âŒ {test_name} - FALLÃ“")
        except Exception as e:
            print(f"ðŸ’¥ {test_name} - ERROR: {e}")
    
    # Resultados finales
    print("\n" + "=" * 80)
    print("ðŸ“‹ RESULTADOS FINALES")
    print("=" * 80)
    
    for i, (test_name, _) in enumerate(tests):
        status = "âœ… PASÃ“" if i < passed else "âŒ FALLÃ“"
        print(f"{test_name:.<40} {status}")
    
    print(f"\nTotal: {passed}/{len(tests)} tests pasaron")
    
    if passed == len(tests):
        print("\nðŸŽ‰ TODOS LOS TESTS PASARON!")
        print("âœ… El sistema maneja mÃºltiples PDFs correctamente")
        print("âœ… El LLM entiende la diferencia entre documentos")
        print("âœ… La estructura del prompt es clara")
        print("âœ… La eliminaciÃ³n y reconstrucciÃ³n funciona")
        print("\nðŸš€ LISTO PARA CONTINUAR CON LA INTERFAZ WEB")
    else:
        print(f"\nâš ï¸ {len(tests) - passed} tests fallaron")
        print("ðŸ”§ Revisar y ajustar antes de continuar")
    
    return 0 if passed == len(tests) else 1

if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Tests interrumpidos")
        sys.exit(1)
    except Exception as e:
        print(f"\nðŸ’¥ Error: {e}")
        sys.exit(1)
